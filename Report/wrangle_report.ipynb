{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92224ff1",
   "metadata": {},
   "source": [
    "# WeRateDogs\n",
    "## A Data-Wrangling project by Muheez Okunade\n",
    "\n",
    "### Wrangle Report\n",
    "\n",
    "This project makes part of the coursework leading to Udacity's Data Analysis Nanodegree (DAND). Its\n",
    "objective is to demonstrate skills for the Data Wrangling phase of the Data Analysis Process. Data\n",
    "Wrangling is a key part in analytics and is typically described as the one where analysts and data\n",
    "scientists spend the most part of their time.\n",
    "The project gathers data from different sources related to the WeRateDogs twitter account, which\n",
    "posts and rates photos of followers' dogs. After assessing and cleaning the data, reports are written\n",
    "to communicate the results of an initial analysis.\n",
    "I thought Data Wrangling was going to be the easiest and fastest of all lessons in the DAND. I swiftly\n",
    "listened to every video and assumed I already knew almost all of it. However, when I started the\n",
    "project, I quickly realized that I needed to put much more work on it. Already in the gathering phase,\n",
    "specifically querying Twitter’s API, it was clear that I needed to go over the material again, take\n",
    "notes, and practice in my own Jupyter Notebook.\n",
    "I found useful the structure (define, code, test) proposed for the cleaning process, but in my clase it\n",
    "was clear that I needed flexibility and iteration. I had to go back to cleaning more, even until the last\n",
    "chart was produced. I believe sticking to the process is a must, especially when dealing with multiple\n",
    "sources of messy and untidy data. Although it was recommended to start by solving tidiness issues,\n",
    "in this case removing first the unnecessary rows with retweets and replies, followed by the\n",
    "organisation in tables of observational units was important.\n",
    "When cleaning the datasets, I felt like I was being able to put into practice many of the skills I have\n",
    "been learning over the last months. Extracting HTML contents from a tag within the column of a\n",
    "pandas dataframe using BeautifulSoup was a nice accomplishment.\n",
    "\n",
    "Some of the issues identified are:\n",
    "    \n",
    "### Quality\n",
    "\n",
    "`twitter-archive-enhanced.csv`\n",
    "\n",
    "- The extracted rating numerators are wrong when they are decimals like 13.5. Status:solved.\n",
    "- source column has innecesary HTML code. Status: solved\n",
    "- some tweets are retweets or replies. Status: solved\n",
    "- timestamp column is not in datatime format. Status: solved\n",
    "- The rating for dog in tweet with id 716439118184652801, 722974582966214656 and 682962037429899265 are wrong. Status: solved\n",
    "- Many dog names are wrong, including hose with id 740373189193256964 and 770414278348247044. Many names are just other words in English. Status: solved\n",
    "- The dog stage for dog in tweet with id 854010172552949760 is wrong. Status: solved\n",
    "- some rows have several identical values in the expanded_url column concatenated by a comma. Status: solved\n",
    "- Tweet_id fields in the three datasets are stored as numeric values and should be strings. Status: solved\n",
    "- Predictions are spread in three columns. Status: solved\n",
    "- Confidence intervals are spread in three columns. Status: solved\n",
    "- Dog tests are spread in three columns. Status: solved\n",
    "`additional twitter data`\n",
    "\n",
    "`more_data` dataframe\n",
    "\n",
    "- Retweet and favorite count columns have float as datatype and should be int. Status: solved\n",
    "\n",
    "\n",
    "### Tidiness\n",
    "\n",
    "`twitter-archive-enhanced.csv`\n",
    "\n",
    "- Dog \"stage\" is spread in four columns. Status: solved\n",
    "- Data about dogs and tweets in a same dataset. Status: solved\n",
    "- The dog's raiting appears both in the \"text\" column and the rating numerator/denominator columns. Status: will not be solved here\n",
    "- The link to the dog's photo is part of the status text and should have own column. Status: will not be solved here\n",
    "`image-predictions.tsv`\n",
    "\n",
    "I have been working with relational databases for a while now, and I had already developed the\n",
    "sense to understand when observational units are not in their own tables. I ended up keeping\n",
    "separate tables for tweets, dogs and predictions. What I wasn’t sure about was whether a master\n",
    "dataset made sense because having different row counts makes the result different as what you\n",
    "expect. The key is to keep in mind whether you want to keep dogs or tweets as main organisational\n",
    "unit in a master dataset.\n",
    "When creating charts for the last section of the project, I really missed R’s ggplot. I started using\n",
    "matplotlib but was quickly drawn to look for other options, which brought me to the Altair library. I\n",
    "read its documentation and plotted my visualizations on it. Although I found Altair intuitive to use,\n",
    "when I looked under the hood I realized that every chart makes a copy of the whole dataset in JSON\n",
    "format, which makes it less than ideal when working with large datasets or when performing EDA\n",
    "with tons of visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a230a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
